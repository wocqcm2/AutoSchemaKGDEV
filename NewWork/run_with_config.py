#!/usr/bin/env python3
"""
ä½¿ç”¨é…ç½®æ–‡ä»¶è¿è¡ŒNewWork Pipeline
è¿™æ˜¯ä½¿ç”¨config.jsoné…ç½®æ–‡ä»¶çš„ç®€åŒ–ç‰ˆæœ¬
"""

import os
import sys
import argparse
from pathlib import Path

# æ·»åŠ è·¯å¾„
current_dir = Path(__file__).parent
sys.path.append(str(current_dir))
sys.path.append(str(current_dir.parent))

from config_loader import ConfigLoader, create_model_client, quick_setup
from direct_concept_pipeline import DirectConceptPipeline


def run_simple_example():
    """ç®€å•ç¤ºä¾‹ï¼šä½¿ç”¨é…ç½®æ–‡ä»¶çš„æœ€å°ç¤ºä¾‹"""
    print("ğŸ”¥ Simple Example with Config File")
    print("=" * 50)
    
    try:
        # 1. åŠ è½½é…ç½®å’Œæ¨¡å‹ï¼ˆä¸€è¡Œä»£ç ï¼‰
        config_loader, model, model_name = quick_setup()
        
        print(f"âœ… Loaded model: {model_name}")
        
        # 2. åˆ›å»ºpipelineé…ç½®
        pipeline_config = config_loader.get_direct_concept_config(
            filename_pattern="Dulce_test",  # ä½¿ç”¨å°æµ‹è¯•æ–‡ä»¶
            output_name="simple_test"
        )
        
        # 3. è¿è¡Œpipeline
        pipeline = DirectConceptPipeline(model, pipeline_config)
        outputs = pipeline.run_full_pipeline("dulce_simple")
        
        print("\nğŸ‰ Success! Generated files:")
        for key, path in outputs.items():
            print(f"   ğŸ“„ {key}: {path}")
            
        return True
        
    except Exception as e:
        print(f"âŒ Simple example failed: {e}")
        import traceback
        traceback.print_exc()
        return False


def run_with_different_models():
    """ä½¿ç”¨ä¸åŒæ¨¡å‹çš„ç¤ºä¾‹"""
    print("\nğŸ”¥ Testing Different Models")
    print("=" * 50)
    
    config_loader = ConfigLoader()
    
    # æ˜¾ç¤ºå¯ç”¨æ¨¡å‹
    models = config_loader.list_available_models()
    print("Available models:")
    for short_name, full_name in models.items():
        print(f"  {short_name}: {full_name}")
    
    # æµ‹è¯•Qwenæ¨¡å‹
    try:
        print(f"\nğŸ¤– Testing Qwen model...")
        model = create_model_client(config_loader, "qwen_235b")
        
        pipeline_config = config_loader.get_direct_concept_config(
            model_name="qwen_235b",
            filename_pattern="Dulce_test",
            output_name="qwen_test",
            batch_size_concept=4,  # å¤§æ¨¡å‹ç”¨å°batch
            temperature=0.1
        )
        
        pipeline = DirectConceptPipeline(model, pipeline_config)
        outputs = pipeline.run_full_pipeline("dulce_qwen")
        
        print("âœ… Qwen model test successful!")
        return True
        
    except Exception as e:
        print(f"âŒ Qwen model test failed: {e}")
        return False


def run_chinese_example():
    """ä¸­æ–‡æ•°æ®å¤„ç†ç¤ºä¾‹"""
    print("\nğŸ”¥ Chinese Text Processing with Config")
    print("=" * 50)
    
    try:
        config_loader, model, model_name = quick_setup()
        
        # ä¸­æ–‡é…ç½®
        pipeline_config = config_loader.get_direct_concept_config(
            filename_pattern="RomanceOfTheThreeKingdom-zh-CN",
            output_name="chinese_test",
            extraction_mode="hierarchical_concept",  # è¦†ç›–é»˜è®¤è®¾ç½®
            language="zh",  # è¦†ç›–é»˜è®¤è®¾ç½®
            batch_size_concept=6
        )
        
        pipeline = DirectConceptPipeline(model, pipeline_config)
        outputs = pipeline.run_full_pipeline("three_kingdoms")
        
        print("âœ… Chinese processing successful!")
        for key, path in outputs.items():
            print(f"   ğŸ“„ {key}: {path}")
            
        return True
        
    except Exception as e:
        print(f"âŒ Chinese processing failed: {e}")
        return False


def run_large_document_example():
    """å¤§æ–‡æ¡£å¤„ç†ç¤ºä¾‹"""
    print("\nğŸ”¥ Large Document Processing with Config")
    print("=" * 50)
    
    try:
        config_loader, model, model_name = quick_setup()
        
        # å¤§æ–‡æ¡£é…ç½®
        pipeline_config = config_loader.get_direct_concept_config(
            filename_pattern="Apple_Environmental_Progress_Report_2024",
            output_name="apple_report",
            batch_size_concept=3,    # å¤§æ–‡æ¡£ç”¨å°batch
            text_chunk_size=600,     # å°chunk
            chunk_overlap=150,       # å¤§é‡å 
            min_concept_frequency=2, # è¿‡æ»¤ä½é¢‘æ¦‚å¿µ
            max_workers=2           # å‡å°‘å¹¶å‘
        )
        
        print("âš ï¸ This will process a large document and may take some time...")
        choice = input("Continue? (y/n): ").lower().strip()
        
        if choice != 'y':
            print("Skipped large document processing")
            return True
        
        pipeline = DirectConceptPipeline(model, pipeline_config)
        outputs = pipeline.run_full_pipeline("apple_environmental")
        
        print("âœ… Large document processing successful!")
        for key, path in outputs.items():
            print(f"   ğŸ“„ {key}: {path}")
            
        return True
        
    except Exception as e:
        print(f"âŒ Large document processing failed: {e}")
        return False


def interactive_mode():
    """äº¤äº’æ¨¡å¼"""
    print("\nğŸ”¥ Interactive Mode")
    print("=" * 50)
    
    config_loader = ConfigLoader()
    
    # æ˜¾ç¤ºé…ç½®æ‘˜è¦
    config_loader.print_config_summary()
    
    while True:
        print("\nğŸ“‹ Available Actions:")
        print("1. Run simple test")
        print("2. Try different models")  
        print("3. Process Chinese text")
        print("4. Process large document")
        print("5. Show config")
        print("6. Quit")
        
        choice = input("\nSelect action (1-6): ").strip()
        
        if choice == '1':
            run_simple_example()
        elif choice == '2':
            run_with_different_models()
        elif choice == '3':
            run_chinese_example()
        elif choice == '4':
            run_large_document_example()
        elif choice == '5':
            config_loader.print_config_summary()
        elif choice == '6':
            break
        else:
            print("âŒ Invalid choice, please select 1-6")


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Run NewWork Pipeline with Config File')
    
    parser.add_argument('--config', default='config.json', help='Config file path')
    parser.add_argument('--model', help='Model name from config')
    parser.add_argument('--data', help='Data filename pattern')
    parser.add_argument('--output', help='Output name')
    parser.add_argument('--mode', choices=['simple', 'models', 'chinese', 'large', 'interactive'], 
                       default='simple', help='Run mode')
    parser.add_argument('--batch-size', type=int, help='Batch size override')
    parser.add_argument('--language', choices=['en', 'zh'], help='Language override')
    
    args = parser.parse_args()
    
    print("ğŸŒŸ NewWork Pipeline with Configuration")
    print("=" * 60)
    
    # æ£€æŸ¥é…ç½®æ–‡ä»¶
    if not os.path.exists(args.config):
        print(f"âŒ Config file not found: {args.config}")
        print("Please make sure config.json exists in the current directory")
        return 1
    
    try:
        # æ ¹æ®æ¨¡å¼è¿è¡Œ
        if args.mode == 'simple':
            success = run_simple_example()
        elif args.mode == 'models':
            success = run_with_different_models()
        elif args.mode == 'chinese':
            success = run_chinese_example()
        elif args.mode == 'large':
            success = run_large_document_example()
        elif args.mode == 'interactive':
            interactive_mode()
            success = True
        else:
            print(f"âŒ Unknown mode: {args.mode}")
            return 1
        
        if success:
            print("\nğŸŠ Pipeline completed successfully!")
            return 0
        else:
            print("\nâŒ Pipeline failed!")
            return 1
    
    except KeyboardInterrupt:
        print("\nâš ï¸ Pipeline interrupted by user")
        return 1
    except Exception as e:
        print(f"\nâŒ Pipeline failed: {e}")
        return 1


if __name__ == "__main__":
    sys.exit(main())