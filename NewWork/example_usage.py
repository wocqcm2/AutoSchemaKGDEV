#!/usr/bin/env python3
"""
Direct Concept Pipeline Usage Example
ç›´æ¥æ¦‚å¿µæå–pipelineçš„ä½¿ç”¨ç¤ºä¾‹
"""

import sys
import os
from openai import OpenAI
from transformers import pipeline
from configparser import ConfigParser

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from direct_concept_pipeline import DirectConceptPipeline, create_default_config


def setup_openai_model():
    """è®¾ç½®OpenAIæ¨¡å‹"""
    # è¯»å–é…ç½®æ–‡ä»¶
    config = ConfigParser()
    config.read('config.ini')
    
    # åˆ›å»ºOpenAIå®¢æˆ·ç«¯
    client = OpenAI(
        api_key=config['settings']['OPENAI_API_KEY']
    )
    
    # å¯¼å…¥LLMGenerator
    sys.path.append('..')  # æ·»åŠ ä¸Šçº§ç›®å½•ä»¥å¯¼å…¥atlas_rag
    from atlas_rag.llm_generator import LLMGenerator
    
    model_name = "gpt-4o"
    llm_generator = LLMGenerator(client, model_name=model_name)
    
    return llm_generator, model_name


def setup_local_model():
    """è®¾ç½®æœ¬åœ°Transformersæ¨¡å‹"""
    model_name = "meta-llama/Llama-3.1-8B-Instruct"
    
    # åˆ›å»ºæœ¬åœ°æ¨¡å‹pipeline
    client = pipeline(
        "text-generation",
        model=model_name,
        device_map="auto",
    )
    
    # å¯¼å…¥LLMGenerator
    sys.path.append('..')
    from atlas_rag.llm_generator import LLMGenerator
    
    llm_generator = LLMGenerator(client, model_name=model_name)
    
    return llm_generator, model_name


def example_basic_usage():
    """åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹"""
    print("ğŸ”¥ Basic Usage Example")
    print("=" * 50)
    
    # 1. è®¾ç½®æ¨¡å‹ï¼ˆé€‰æ‹©ä¸€ç§ï¼‰
    try:
        # é€‰é¡¹1: ä½¿ç”¨OpenAI API
        model, model_name = setup_openai_model()
        print(f"âœ… Using OpenAI model: {model_name}")
    except:
        try:
            # é€‰é¡¹2: ä½¿ç”¨æœ¬åœ°æ¨¡å‹
            model, model_name = setup_local_model()
            print(f"âœ… Using local model: {model_name}")
        except Exception as e:
            print(f"âŒ Failed to setup model: {e}")
            print("Please check your model configuration.")
            return
    
    # 2. åˆ›å»ºé…ç½®
    config = create_default_config(
        model_path=model_name,
        data_directory="../example_data",  # ä½¿ç”¨é¡¹ç›®ä¸­çš„ç¤ºä¾‹æ•°æ®
        filename_pattern="Dulce",  # å¤„ç†Dulceæ•°æ®
        output_directory="NewWork/output/basic_example",
        extraction_mode="passage_concept",  # æˆ–è€… "hierarchical_concept"
        language="en"  # æˆ–è€… "zh"
    )
    
    # 3. åˆ›å»ºpipeline
    pipeline_instance = DirectConceptPipeline(model, config)
    
    # 4. è¿è¡Œå®Œæ•´pipeline
    try:
        outputs = pipeline_instance.run_full_pipeline("dulce_concepts")
        
        print("\nğŸ‰ Success! Generated files:")
        for key, path in outputs.items():
            print(f"   ğŸ“„ {key}: {path}")
        
    except Exception as e:
        print(f"âŒ Pipeline failed: {e}")


def example_step_by_step():
    """åˆ†æ­¥æ‰§è¡Œç¤ºä¾‹"""
    print("\nğŸ”¥ Step-by-Step Execution Example")
    print("=" * 50)
    
    # è®¾ç½®æ¨¡å‹
    try:
        model, model_name = setup_openai_model()
    except:
        model, model_name = setup_local_model()
    
    # åˆ›å»ºé…ç½®
    config = create_default_config(
        model_path=model_name,
        data_directory="../example_data",
        filename_pattern="Apple_Environmental",  # å¤„ç†è‹¹æœç¯å¢ƒæŠ¥å‘Š
        output_directory="NewWork/output/step_example",
        extraction_mode="hierarchical_concept",  # ä½¿ç”¨å±‚æ¬¡æ¦‚å¿µæ¨¡å¼
        language="en"
    )
    
    pipeline_instance = DirectConceptPipeline(model, config)
    
    try:
        # æ­¥éª¤1: ä»…æå–æ¦‚å¿µ
        print("\nğŸš€ Step 1: Extract concepts only...")
        extraction_results = pipeline_instance.run_extraction_only()
        
        print(f"âœ… Concepts extracted to: {extraction_results['concepts_csv']}")
        print(f"âœ… Relationships extracted to: {extraction_results['relationships_csv']}")
        
        # æ­¥éª¤2: ä»CSVæ„å»ºå›¾
        print("\nğŸ”§ Step 2: Build graph from CSV...")
        graph_results = pipeline_instance.run_graph_only(
            extraction_results['concepts_csv'],
            extraction_results['relationships_csv'],
            "apple_environmental_graph"
        )
        
        print(f"âœ… Graph saved to: {graph_results['graphml_file']}")
        print(f"âœ… Statistics: {graph_results['statistics']}")
        
    except Exception as e:
        print(f"âŒ Step-by-step execution failed: {e}")


def example_chinese_text():
    """ä¸­æ–‡æ–‡æœ¬å¤„ç†ç¤ºä¾‹"""
    print("\nğŸ”¥ Chinese Text Processing Example")
    print("=" * 50)
    
    # åˆ›å»ºä¸­æ–‡ç¤ºä¾‹æ•°æ®
    os.makedirs("NewWork/example_data", exist_ok=True)
    
    chinese_example = {
        "text": """
        äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå®ƒè‡´åŠ›äºç ”ç©¶ã€å¼€å‘ç”¨äºæ¨¡æ‹Ÿã€å»¶ä¼¸å’Œæ‰©å±•äººçš„æ™ºèƒ½çš„ç†è®ºã€æ–¹æ³•ã€æŠ€æœ¯åŠåº”ç”¨ç³»ç»Ÿã€‚
        äººå·¥æ™ºèƒ½çš„ç ”ç©¶é¢†åŸŸåŒ…æ‹¬æœºå™¨å­¦ä¹ ã€æ·±åº¦å­¦ä¹ ã€è‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰ç­‰ã€‚
        æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„æ ¸å¿ƒæŠ€æœ¯ä¹‹ä¸€ï¼Œé€šè¿‡ç®—æ³•ä½¿è®¡ç®—æœºèƒ½å¤Ÿè‡ªåŠ¨å­¦ä¹ å’Œæ”¹è¿›ã€‚
        æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œä½¿ç”¨ç¥ç»ç½‘ç»œæ¥æ¨¡æ‹Ÿäººè„‘çš„å·¥ä½œæ–¹å¼ã€‚
        """,
        "metadata": {
            "file_id": "ai_intro_zh",
            "lang": "zh",
            "title": "äººå·¥æ™ºèƒ½ç®€ä»‹"
        }
    }
    
    # ä¿å­˜ä¸­æ–‡ç¤ºä¾‹æ•°æ®
    import json
    with open("NewWork/example_data/chinese_example.json", "w", encoding="utf-8") as f:
        json.dump([chinese_example], f, ensure_ascii=False, indent=2)
    
    # è®¾ç½®æ¨¡å‹
    try:
        model, model_name = setup_openai_model()
    except:
        model, model_name = setup_local_model()
    
    # åˆ›å»ºä¸­æ–‡é…ç½®
    config = create_default_config(
        model_path=model_name,
        data_directory="NewWork/example_data",
        filename_pattern="chinese_example",
        output_directory="NewWork/output/chinese_example",
        extraction_mode="passage_concept",
        language="zh"  # ä½¿ç”¨ä¸­æ–‡
    )
    
    pipeline_instance = DirectConceptPipeline(model, config)
    
    try:
        outputs = pipeline_instance.run_full_pipeline("chinese_ai_concepts")
        
        print("\nğŸ‰ Chinese text processing completed!")
        for key, path in outputs.items():
            print(f"   ğŸ“„ {key}: {path}")
        
    except Exception as e:
        print(f"âŒ Chinese text processing failed: {e}")


def example_custom_config():
    """è‡ªå®šä¹‰é…ç½®ç¤ºä¾‹"""
    print("\nğŸ”¥ Custom Configuration Example")
    print("=" * 50)
    
    # è®¾ç½®æ¨¡å‹
    try:
        model, model_name = setup_openai_model()
    except:
        model, model_name = setup_local_model()
    
    # å¯¼å…¥é…ç½®ç±»
    from direct_concept_config import DirectConceptConfig
    
    # åˆ›å»ºè‡ªå®šä¹‰é…ç½®
    custom_config = DirectConceptConfig(
        # æ¨¡å‹é…ç½®
        model_path=model_name,
        max_new_tokens=3072,  # æ›´å¤§çš„è¾“å‡ºé•¿åº¦
        temperature=0.3,      # æ›´ä½çš„æ¸©åº¦ï¼Œæ›´ç¡®å®šæ€§
        max_workers=5,        # æ›´å¤šå¹¶è¡Œworkers
        
        # æ•°æ®é…ç½®
        data_directory="../example_data",
        filename_pattern="CICGPC",
        output_directory="NewWork/output/custom_example",
        
        # å¤„ç†é…ç½®
        batch_size_concept=4,    # è¾ƒå°çš„batch size
        text_chunk_size=800,     # è¾ƒå°çš„æ–‡æœ¬å—
        chunk_overlap=150,       # æ›´å¤§çš„é‡å 
        
        # æ¦‚å¿µæå–é…ç½®
        extraction_mode="hierarchical_concept",  # å±‚æ¬¡æ¦‚å¿µæ¨¡å¼
        language="en",
        
        # å›¾æ„å»ºé…ç½®
        include_abstraction_levels=True,
        include_hierarchical_relations=True,
        min_concept_frequency=2,  # åªä¿ç•™å‡ºç°2æ¬¡ä»¥ä¸Šçš„æ¦‚å¿µ
        
        # è´¨é‡æ§åˆ¶
        normalize_concept_names=True,
        filter_low_quality_concepts=True,
        
        # è°ƒè¯•é…ç½®
        debug_mode=True,
        record_usage=True,
        save_intermediate_results=True
    )
    
    pipeline_instance = DirectConceptPipeline(model, custom_config)
    
    try:
        outputs = pipeline_instance.run_full_pipeline("cicgpc_concepts")
        
        print("\nğŸ‰ Custom configuration processing completed!")
        for key, path in outputs.items():
            print(f"   ğŸ“„ {key}: {path}")
        
    except Exception as e:
        print(f"âŒ Custom configuration processing failed: {e}")


def main():
    """ä¸»å‡½æ•° - è¿è¡Œæ‰€æœ‰ç¤ºä¾‹"""
    print("ğŸŒŸ Direct Concept Pipeline Examples")
    print("=" * 60)
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs("NewWork/output", exist_ok=True)
    
    try:
        # ç¤ºä¾‹1: åŸºæœ¬ä½¿ç”¨
        example_basic_usage()
        
        # ç¤ºä¾‹2: åˆ†æ­¥æ‰§è¡Œ
        example_step_by_step()
        
        # ç¤ºä¾‹3: ä¸­æ–‡æ–‡æœ¬å¤„ç†
        example_chinese_text()
        
        # ç¤ºä¾‹4: è‡ªå®šä¹‰é…ç½®
        example_custom_config()
        
        print("\nğŸŠ All examples completed successfully!")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ Examples interrupted by user")
    except Exception as e:
        print(f"\nâŒ Examples failed: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main() 