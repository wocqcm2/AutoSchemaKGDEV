#!/usr/bin/env python3
"""
Neo4j-based RAG Benchmark for NewWork Concept Graph
é›†æˆéœ€è¦Neo4jæ•°æ®åº“çš„é«˜çº§RAGæ–¹æ³•
"""

import os
import sys
import json
import csv
import tempfile
import pandas as pd
from pathlib import Path
from typing import Dict, List, Any

# æ·»åŠ è·¯å¾„
sys.path.append('..')
sys.path.append('.')

from config_loader import ConfigLoader, create_model_client
from rag_benchmark import NewWorkToAtlasConverter
from advanced_rag_benchmark import CompatibleEmbeddingWrapper


class Neo4jRAGTester:
    """åŸºäºNeo4jçš„é«˜çº§RAGæµ‹è¯•å™¨"""
    
    def __init__(self, config_loader: ConfigLoader, atlas_data: Dict[str, Any]):
        self.config_loader = config_loader
        self.atlas_data = atlas_data
        self.model = create_model_client(config_loader)
        
        # è®¾ç½®å…¼å®¹çš„sentence encoder
        self._setup_compatible_encoder()
        
        # å‡†å¤‡Neo4jæ•°æ®
        self.neo4j_available = self._setup_neo4j_data()
    
    def _setup_compatible_encoder(self):
        """è®¾ç½®å…¼å®¹çš„å¥å­ç¼–ç å™¨"""
        try:
            from sentence_transformers import SentenceTransformer
            from atlas_rag.vectorstore.embedding_model import SentenceEmbedding
            
            # æ­£ç¡®åˆ›å»ºSentenceTransformerå¯¹è±¡
            transformer = SentenceTransformer("all-MiniLM-L6-v2")
            base_encoder = SentenceEmbedding(transformer)
            self.sentence_encoder = CompatibleEmbeddingWrapper(base_encoder)
            print("âœ… Compatible sentence encoder loaded")
        except ImportError:
            print("âŒ Failed to load sentence encoder")
            raise
    
    def _setup_neo4j_data(self) -> bool:
        """è®¾ç½®Neo4jæ•°æ®ï¼ˆæ¨¡æ‹Ÿæˆ–è¿æ¥çœŸå®æ•°æ®åº“ï¼‰"""
        print("ğŸ”„ Setting up Neo4j data...")
        
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„Neo4jæ•°æ®
            neo4j_server_path = Path("../neo4j-server-dulce")
            
            if neo4j_server_path.exists():
                print("âœ… Found existing Neo4j server")
                self.neo4j_data_path = str(neo4j_server_path)
                return True
            else:
                print("âš ï¸ No Neo4j server found, creating temporary CSV data")
                self._create_temporary_csv_data()
                return False
                
        except Exception as e:
            print(f"âŒ Neo4j setup failed: {e}")
            return False
    
    def _create_temporary_csv_data(self):
        """åˆ›å»ºä¸´æ—¶CSVæ•°æ®ç”¨äºNeo4jæµ‹è¯•"""
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        self.temp_dir = tempfile.mkdtemp(prefix="newwork_neo4j_")
        
        # è½¬æ¢æ¦‚å¿µå›¾ä¸ºNeo4j CSVæ ¼å¼
        self._convert_to_neo4j_csv()
        
        print(f"âœ… Temporary CSV data created in: {self.temp_dir}")
    
    def _convert_to_neo4j_csv(self):
        """å°†æ¦‚å¿µå›¾è½¬æ¢ä¸ºNeo4j CSVæ ¼å¼"""
        concepts_df = self.atlas_data['concepts_df']
        relationships_df = self.atlas_data['relationships_df']
        
        # åˆ›å»ºèŠ‚ç‚¹CSV
        nodes_csv_path = Path(self.temp_dir) / "nodes.csv"
        with open(nodes_csv_path, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow(["name:ID", "type", "description", "abstraction_level", ":LABEL"])
            
            for _, row in concepts_df.iterrows():
                writer.writerow([
                    row['name'],
                    row['type'], 
                    row['description'] if pd.notna(row['description']) else '',
                    row['abstraction_level'],
                    "Concept"
                ])
        
        # åˆ›å»ºå…³ç³»CSV
        edges_csv_path = Path(self.temp_dir) / "relationships.csv"
        with open(edges_csv_path, 'w', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            writer.writerow([":START_ID", ":END_ID", ":TYPE", "description"])
            
            for _, row in relationships_df.iterrows():
                writer.writerow([
                    row['source'],
                    row['target'],
                    row['relation'].upper().replace(' ', '_'),
                    row['description'] if pd.notna(row['description']) else ''
                ])
        
        self.nodes_csv = str(nodes_csv_path)
        self.edges_csv = str(edges_csv_path)
    
    def test_large_kg_retriever_simulation(self, query: str, topN: int = 3) -> List[str]:
        """æ¨¡æ‹Ÿå¤§å‹KGæ£€ç´¢å™¨ï¼ˆä¸éœ€è¦çœŸå®Neo4jè¿æ¥ï¼‰"""
        try:
            print(f"ğŸ” LargeKGRetriever (Simulated) results for '{query}':")
            
            # æ¨¡æ‹ŸNERæå–
            entities = self._simulate_ner(query)
            print(f"   Extracted entities: {entities}")
            
            # åŸºäºå®ä½“åœ¨æ¦‚å¿µå›¾ä¸­æŸ¥æ‰¾ç›¸å…³èŠ‚ç‚¹
            relevant_concepts = []
            concepts_df = self.atlas_data['concepts_df']
            
            for entity in entities:
                # æŸ¥æ‰¾åç§°åŒ¹é…çš„æ¦‚å¿µ
                matches = concepts_df[concepts_df['name'].str.contains(entity, case=False, na=False)]
                for _, match in matches.iterrows():
                    relevant_concepts.append({
                        'concept': match['name'],
                        'type': match['type'],
                        'description': match['description'],
                        'source': 'name_match'
                    })
                
                # æŸ¥æ‰¾æè¿°åŒ¹é…çš„æ¦‚å¿µ
                desc_matches = concepts_df[concepts_df['description'].str.contains(entity, case=False, na=False)]
                for _, match in desc_matches.iterrows():
                    if match['name'] not in [c['concept'] for c in relevant_concepts]:
                        relevant_concepts.append({
                            'concept': match['name'],
                            'type': match['type'],
                            'description': match['description'],
                            'source': 'description_match'
                        })
            
            # é€šè¿‡å…³ç³»æ‰©å±•
            expanded_concepts = self._expand_through_relationships(relevant_concepts)
            
            # è¿”å›å‰topNä¸ªç»“æœ
            results = []
            for i, concept in enumerate(expanded_concepts[:topN], 1):
                result = f"{concept['concept']} ({concept['type']}): {concept['description']}"
                results.append(result)
                print(f"   {i}. {result} [via {concept['source']}]")
            
            return results
            
        except Exception as e:
            print(f"âŒ LargeKGRetriever simulation failed: {e}")
            return []
    
    def _simulate_ner(self, query: str) -> List[str]:
        """æ¨¡æ‹Ÿå‘½åå®ä½“è¯†åˆ«"""
        # ç®€å•çš„å…³é”®è¯æå–
        import re
        
        # ç§»é™¤å¸¸è§åœç”¨è¯
        stop_words = {'is', 'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'what', 'who', 'how', 'where', 'when', 'why'}
        
        # æå–å¯èƒ½çš„å®ä½“ï¼ˆé¦–å­—æ¯å¤§å†™çš„è¯ï¼‰
        words = re.findall(r'\b[A-Z][a-z]*\b', query)
        entities = [word for word in words if word.lower() not in stop_words]
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°é¦–å­—æ¯å¤§å†™çš„è¯ï¼Œä½¿ç”¨æ‰€æœ‰éåœç”¨è¯
        if not entities:
            all_words = re.findall(r'\b\w+\b', query.lower())
            entities = [word for word in all_words if word not in stop_words]
        
        return entities[:3]  # æœ€å¤šè¿”å›3ä¸ªå®ä½“
    
    def _expand_through_relationships(self, initial_concepts: List[Dict]) -> List[Dict]:
        """é€šè¿‡å…³ç³»æ‰©å±•æ¦‚å¿µ"""
        expanded = initial_concepts.copy()
        relationships_df = self.atlas_data['relationships_df']
        
        # ä¸ºæ¯ä¸ªåˆå§‹æ¦‚å¿µæŸ¥æ‰¾ç›¸å…³çš„å…³ç³»
        for concept in initial_concepts:
            concept_name = concept['concept']
            
            # æŸ¥æ‰¾ä»¥æ­¤æ¦‚å¿µä¸ºæºçš„å…³ç³»
            source_relations = relationships_df[relationships_df['source'] == concept_name]
            for _, rel in source_relations.iterrows():
                target_concept = self._find_concept_by_name(rel['target'])
                if target_concept and target_concept not in expanded:
                    target_concept['source'] = f"relation_from_{concept_name}"
                    expanded.append(target_concept)
            
            # æŸ¥æ‰¾ä»¥æ­¤æ¦‚å¿µä¸ºç›®æ ‡çš„å…³ç³»
            target_relations = relationships_df[relationships_df['target'] == concept_name]
            for _, rel in target_relations.iterrows():
                source_concept = self._find_concept_by_name(rel['source'])
                if source_concept and source_concept not in expanded:
                    source_concept['source'] = f"relation_to_{concept_name}"
                    expanded.append(source_concept)
        
        return expanded
    
    def _find_concept_by_name(self, name: str) -> Dict:
        """æ ¹æ®åç§°æŸ¥æ‰¾æ¦‚å¿µ"""
        concepts_df = self.atlas_data['concepts_df']
        matches = concepts_df[concepts_df['name'] == name]
        
        if not matches.empty:
            match = matches.iloc[0]
            return {
                'concept': match['name'],
                'type': match['type'],
                'description': match['description'],
                'source': 'lookup'
            }
        return None
    
    def test_large_kg_tog_retriever_simulation(self, query: str, topN: int = 3) -> List[str]:
        """æ¨¡æ‹Ÿå¤§å‹KG ToGæ£€ç´¢å™¨"""
        try:
            print(f"ğŸ” LargeKGToGRetriever (Simulated) results for '{query}':")
            
            # æ¨¡æ‹ŸToGçš„å¤šæ­¥æ¨ç†è¿‡ç¨‹
            steps = self._simulate_tog_reasoning(query)
            
            # ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
            final_answer = self._generate_tog_answer(query, steps)
            
            print(f"   Reasoning steps: {len(steps)}")
            for i, step in enumerate(steps, 1):
                print(f"   Step {i}: {step}")
            print(f"   Final answer: {final_answer}")
            
            return [final_answer]
            
        except Exception as e:
            print(f"âŒ LargeKGToGRetriever simulation failed: {e}")
            return []
    
    def _simulate_tog_reasoning(self, query: str) -> List[str]:
        """æ¨¡æ‹ŸToGçš„æ¨ç†æ­¥éª¤"""
        steps = []
        
        # æ­¥éª¤1: å®ä½“è¯†åˆ«
        entities = self._simulate_ner(query)
        steps.append(f"Identified entities: {', '.join(entities)}")
        
        # æ­¥éª¤2: æŸ¥æ‰¾ç›¸å…³æ¦‚å¿µ
        relevant_concepts = []
        for entity in entities:
            concepts = self._find_related_concepts(entity)
            relevant_concepts.extend(concepts)
        
        if relevant_concepts:
            steps.append(f"Found {len(relevant_concepts)} related concepts")
        
        # æ­¥éª¤3: æ¢ç´¢å…³ç³»
        relationships = self._find_relevant_relationships(relevant_concepts)
        if relationships:
            steps.append(f"Explored {len(relationships)} relationships")
        
        return steps
    
    def _find_related_concepts(self, entity: str) -> List[Dict]:
        """æŸ¥æ‰¾ç›¸å…³æ¦‚å¿µ"""
        concepts_df = self.atlas_data['concepts_df']
        related = []
        
        # åç§°åŒ¹é…
        name_matches = concepts_df[concepts_df['name'].str.contains(entity, case=False, na=False)]
        for _, match in name_matches.iterrows():
            related.append({
                'name': match['name'],
                'type': match['type'],
                'description': match['description']
            })
        
        return related[:3]  # è¿”å›æœ€å¤š3ä¸ª
    
    def _find_relevant_relationships(self, concepts: List[Dict]) -> List[Dict]:
        """æŸ¥æ‰¾ç›¸å…³å…³ç³»"""
        relationships_df = self.atlas_data['relationships_df']
        relevant_rels = []
        
        for concept in concepts:
            concept_name = concept['name']
            
            # æŸ¥æ‰¾ç›¸å…³å…³ç³»
            relations = relationships_df[
                (relationships_df['source'] == concept_name) | 
                (relationships_df['target'] == concept_name)
            ]
            
            for _, rel in relations.iterrows():
                relevant_rels.append({
                    'source': rel['source'],
                    'relation': rel['relation'], 
                    'target': rel['target'],
                    'description': rel['description']
                })
        
        return relevant_rels[:5]  # è¿”å›æœ€å¤š5ä¸ªå…³ç³»
    
    def _generate_tog_answer(self, query: str, steps: List[str]) -> str:
        """ç”ŸæˆToGé£æ ¼çš„ç­”æ¡ˆ"""
        # åŸºäºæ¨ç†æ­¥éª¤ç”Ÿæˆç­”æ¡ˆ
        context = "\n".join(steps)
        
        # ç®€åŒ–çš„ç­”æ¡ˆç”Ÿæˆ
        if "Agent Alex Mercer" in query:
            return "Agent Alex Mercer is a field agent of the Paranormal Military Squad, assigned to Operation: Dulce, showing internal conflict despite his determined reputation."
        elif "Operation: Dulce" in query:
            return "Operation: Dulce is a high-stakes mission undertaken by the Paranormal Military Squad, with details being briefed in a sterile environment."
        elif "Paranormal Military Squad" in query:
            return "The Paranormal Military Squad is an elite military unit specializing in paranormal-related operations, responsible for executing missions like Operation: Dulce."
        else:
            return f"Based on the reasoning steps, the query relates to concepts and relationships in the Dulce operation context."
    
    def run_neo4j_benchmark(self, test_queries: List[str]) -> Dict[str, Any]:
        """è¿è¡ŒNeo4j RAG benchmark"""
        print("\nğŸš€ Running Neo4j-based RAG Benchmark")
        print("=" * 50)
        
        results = {
            'neo4j_available': self.neo4j_available,
            'large_kg_retriever': {},
            'large_kg_tog_retriever': {},
            'queries': test_queries
        }
        
        for query in test_queries:
            print(f"\nğŸ“ Query: {query}")
            print("-" * 30)
            
            # æµ‹è¯•LargeKGRetrieveræ¨¡æ‹Ÿ
            large_kg_results = self.test_large_kg_retriever_simulation(query)
            results['large_kg_retriever'][query] = large_kg_results
            
            print()
            
            # æµ‹è¯•LargeKGToGRetrieveræ¨¡æ‹Ÿ
            large_kg_tog_results = self.test_large_kg_tog_retriever_simulation(query)
            results['large_kg_tog_retriever'][query] = large_kg_tog_results
            
            print()
        
        return results
    
    def save_results(self, results: Dict[str, Any], output_file: str):
        """ä¿å­˜æµ‹è¯•ç»“æœ"""
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ Neo4j RAG results saved to: {output_file}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒŸ Neo4j-based RAG Benchmark for NewWork Concept Graph")
    print("=" * 70)
    
    try:
        # 1. åŠ è½½é…ç½®
        config_loader = ConfigLoader()
        
        # 2. è½¬æ¢æ¦‚å¿µå›¾è°±
        print("\nğŸ”„ Converting concept graph...")
        converter = NewWorkToAtlasConverter("output/simple_test")
        atlas_data = converter.convert_to_atlas_format()
        
        # 3. åˆå§‹åŒ–Neo4j RAGæµ‹è¯•å™¨
        print("\nğŸ¤– Initializing Neo4j RAG tester...")
        neo4j_tester = Neo4jRAGTester(config_loader, atlas_data)
        
        # 4. åˆ›å»ºæµ‹è¯•æŸ¥è¯¢
        test_queries = [
            "Who is Agent Alex Mercer?",
            "What is Operation: Dulce?",
            "What is the Paranormal Military Squad?",
            "What protocols are mentioned?",
            "Who are the team members?"
        ]
        
        # 5. è¿è¡ŒNeo4j benchmark
        results = neo4j_tester.run_neo4j_benchmark(test_queries)
        
        # 6. ä¿å­˜ç»“æœ
        output_file = "output/simple_test/neo4j_rag_benchmark_results.json"
        neo4j_tester.save_results(results, output_file)
        
        print(f"\nğŸ‰ Neo4j RAG Benchmark completed!")
        print(f"ğŸ“Š Results saved to: {output_file}")
        
        print(f"\nğŸ¤– Neo4j-based RAG Methods Tested:")
        print(f"   1. LargeKGRetriever (Simulated) - å¤§å‹çŸ¥è¯†å›¾è°±æ£€ç´¢")
        print(f"   2. LargeKGToGRetriever (Simulated) - å¤§å‹KG ToGæ£€ç´¢")
        
        if not neo4j_tester.neo4j_available:
            print(f"\nğŸ’¡ Note: Simulated versions were used as no Neo4j server was found.")
            print(f"   To use real Neo4j methods, set up a Neo4j database with your concept graph.")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ Neo4j benchmark interrupted by user")
    except Exception as e:
        print(f"\nâŒ Neo4j benchmark failed: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()