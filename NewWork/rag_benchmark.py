#!/usr/bin/env python3
"""
NewWork Concept Graph RAG Benchmark
å°†NewWorkç”Ÿæˆçš„æ¦‚å¿µå›¾è°±é›†æˆåˆ°AutoSchemaKG RAGç³»ç»Ÿä¸­è¿›è¡Œæµ‹è¯•
"""

import os
import sys
import json
import pandas as pd
import pickle
import networkx as nx
import numpy as np
from pathlib import Path
from typing import Dict, List, Any

# æ·»åŠ è·¯å¾„
sys.path.append('..')
sys.path.append('.')

from config_loader import ConfigLoader, create_model_client


class NewWorkToAtlasConverter:
    """å°†NewWorkæ¦‚å¿µå›¾è°±è½¬æ¢ä¸ºAtlas RAGå…¼å®¹æ ¼å¼"""
    
    def __init__(self, output_path: str):
        """
        Args:
            output_path: NewWorkè¾“å‡ºè·¯å¾„ï¼Œå¦‚ "output/simple_test"
        """
        self.output_path = Path(output_path)
        self.concepts_csv = self.output_path / "concept_csv" / "concepts_Dulce_test.csv"
        self.relationships_csv = self.output_path / "concept_csv" / "relationships_Dulce_test.csv"
        self.graph_pkl = self.output_path / "graph" / "dulce_simple.pkl"
        
    def load_concept_graph(self) -> nx.Graph:
        """åŠ è½½æ¦‚å¿µå›¾"""
        if self.graph_pkl.exists():
            with open(self.graph_pkl, 'rb') as f:
                return pickle.load(f)
        else:
            raise FileNotFoundError(f"Graph file not found: {self.graph_pkl}")
    
    def load_concepts_and_relations(self) -> tuple:
        """åŠ è½½æ¦‚å¿µå’Œå…³ç³»æ•°æ®"""
        concepts_df = pd.read_csv(self.concepts_csv)
        relationships_df = pd.read_csv(self.relationships_csv)
        return concepts_df, relationships_df
    
    def convert_to_atlas_format(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºAtlas RAGå…¼å®¹æ ¼å¼"""
        print("ğŸ”„ Converting NewWork graph to Atlas format...")
        
        # åŠ è½½æ•°æ®
        G = self.load_concept_graph()
        concepts_df, relationships_df = self.load_concepts_and_relations()
        
        # æ„å»ºèŠ‚ç‚¹åˆ—è¡¨
        node_list = []
        node_dict = {}
        
        for idx, row in concepts_df.iterrows():
            node_id = str(idx)
            node_data = {
                'id': row['name'],
                'text': row['description'] if pd.notna(row['description']) else row['name'],
                'type': row['type'],
                'abstraction_level': row['abstraction_level']
            }
            node_list.append(node_id)
            node_dict[node_id] = node_data
            
            # æ·»åŠ åˆ°NetworkXå›¾ä¸­
            if node_id not in G.nodes:
                G.add_node(node_id, **node_data)
        
        # æ„å»ºè¾¹åˆ—è¡¨
        edge_list = []
        edge_dict = {}
        
        for idx, row in relationships_df.iterrows():
            source_name = row['source']
            target_name = row['target']
            
            # æŸ¥æ‰¾å¯¹åº”çš„èŠ‚ç‚¹ID
            source_id = None
            target_id = None
            
            for node_idx, concept_row in concepts_df.iterrows():
                if concept_row['name'] == source_name:
                    source_id = str(node_idx)
                if concept_row['name'] == target_name:
                    target_id = str(node_idx)
            
            if source_id and target_id:
                edge_key = (source_id, target_id)
                edge_list.append(edge_key)
                
                edge_data = {
                    'relation': row['relation'],
                    'description': row['description'] if pd.notna(row['description']) else row['relation']
                }
                edge_dict[edge_key] = edge_data
                
                # æ·»åŠ åˆ°NetworkXå›¾ä¸­
                G.add_edge(source_id, target_id, **edge_data)
        
        print(f"âœ… Converted: {len(node_list)} nodes, {len(edge_list)} edges")
        
        return {
            'KG': G,
            'node_list': node_list,
            'edge_list': edge_list,
            'node_dict': node_dict,
            'edge_dict': edge_dict,
            'concepts_df': concepts_df,
            'relationships_df': relationships_df
        }


class NewWorkRAGTester:
    """NewWorkæ¦‚å¿µå›¾çš„RAGæµ‹è¯•å™¨"""
    
    def __init__(self, config_loader: ConfigLoader, atlas_data: Dict[str, Any]):
        """
        Args:
            config_loader: NewWorké…ç½®åŠ è½½å™¨
            atlas_data: è½¬æ¢åçš„Atlasæ ¼å¼æ•°æ®
        """
        self.config_loader = config_loader
        self.atlas_data = atlas_data
        self.model = create_model_client(config_loader)
        
        # è®¾ç½®å¥å­ç¼–ç å™¨
        self._setup_sentence_encoder()
        
        # åˆ›å»ºembeddings
        self._create_embeddings()
    
    def _setup_sentence_encoder(self):
        """è®¾ç½®å¥å­ç¼–ç å™¨"""
        try:
            from sentence_transformers import SentenceTransformer
            from atlas_rag.vectorstore.embedding_model import SentenceEmbedding
            
            # æ­£ç¡®åˆ›å»ºSentenceTransformerå¯¹è±¡
            transformer = SentenceTransformer("all-MiniLM-L6-v2")
            self.sentence_encoder = SentenceEmbedding(transformer)
            print("âœ… Sentence encoder loaded: all-MiniLM-L6-v2")
        except ImportError:
            print("âŒ Failed to load Atlas sentence encoder")
            raise
    
    def _create_embeddings(self):
        """åˆ›å»ºèŠ‚ç‚¹å’Œè¾¹çš„embeddings"""
        print("ğŸ”„ Creating embeddings for nodes and edges...")
        
        # èŠ‚ç‚¹embeddings
        node_texts = []
        for node_id in self.atlas_data['node_list']:
            node_data = self.atlas_data['KG'].nodes[node_id]
            text = f"{node_data.get('id', '')} {node_data.get('text', '')}"
            node_texts.append(text)
        
        # ç›´æ¥ä½¿ç”¨SentenceTransformerè¿›è¡Œç¼–ç 
        node_embeddings = self.sentence_encoder.sentence_encoder.encode(node_texts)
        
        # è¾¹embeddings
        edge_texts = []
        for edge in self.atlas_data['edge_list']:
            source_node = self.atlas_data['KG'].nodes[edge[0]]
            target_node = self.atlas_data['KG'].nodes[edge[1]]
            edge_data = self.atlas_data['KG'].edges[edge]
            
            text = f"{source_node.get('id', '')} {edge_data.get('relation', '')} {target_node.get('id', '')}"
            edge_texts.append(text)
        
        # ç›´æ¥ä½¿ç”¨SentenceTransformerè¿›è¡Œç¼–ç 
        edge_embeddings = self.sentence_encoder.sentence_encoder.encode(edge_texts)
        
        # åˆ›å»ºFAISSç´¢å¼•
        import faiss
        
        # èŠ‚ç‚¹FAISSç´¢å¼•
        node_faiss_index = faiss.IndexFlatIP(node_embeddings.shape[1])
        node_faiss_index.add(node_embeddings.astype('float32'))
        
        # è¾¹FAISSç´¢å¼•  
        edge_faiss_index = faiss.IndexFlatIP(edge_embeddings.shape[1])
        edge_faiss_index.add(edge_embeddings.astype('float32'))
        
        self.atlas_data.update({
            'node_embeddings': node_embeddings,
            'edge_embeddings': edge_embeddings,
            'node_faiss_index': node_faiss_index,
            'edge_faiss_index': edge_faiss_index
        })
        
        print("âœ… Embeddings and FAISS indices created")
    
    def test_simple_graph_retriever(self, query: str, topN: int = 5) -> List[str]:
        """æµ‹è¯•ç®€å•å›¾æ£€ç´¢å™¨ï¼ˆè‡ªå®šä¹‰å®ç°ï¼‰"""
        try:
            print(f"ğŸ” Simple Graph Retriever results for '{query}':")
            
            # ä½¿ç”¨è‡ªå®šä¹‰çš„ç®€å•æ£€ç´¢æ–¹æ³•
            query_embedding = self.sentence_encoder.sentence_encoder.encode([query])
            
            # æœç´¢æœ€ç›¸ä¼¼çš„è¾¹
            D, I = self.atlas_data['edge_faiss_index'].search(query_embedding, topN)
            
            results = []
            for i, (distance, index) in enumerate(zip(D[0], I[0]), 1):
                if index < len(self.atlas_data['edge_list']):
                    edge = self.atlas_data['edge_list'][index]
                    source_node = self.atlas_data['KG'].nodes[edge[0]]
                    target_node = self.atlas_data['KG'].nodes[edge[1]]
                    edge_data = self.atlas_data['KG'].edges[edge]
                    
                    result = f"{source_node.get('id', edge[0])} {edge_data.get('relation', '')} {target_node.get('id', edge[1])}"
                    results.append(result)
                    print(f"   {i}. {result} (similarity: {1-distance:.3f})")
            
            return results
            
        except Exception as e:
            print(f"âŒ Simple Graph Retriever failed: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def test_node_retriever(self, query: str, topN: int = 5) -> List[str]:
        """æµ‹è¯•èŠ‚ç‚¹æ£€ç´¢å™¨ï¼ˆè‡ªå®šä¹‰å®ç°ï¼‰"""
        try:
            print(f"ğŸ” Node Retriever results for '{query}':")
            
            # ä½¿ç”¨èŠ‚ç‚¹embeddingsè¿›è¡Œæ£€ç´¢
            query_embedding = self.sentence_encoder.sentence_encoder.encode([query])
            
            # æœç´¢æœ€ç›¸ä¼¼çš„èŠ‚ç‚¹
            D, I = self.atlas_data['node_faiss_index'].search(query_embedding, topN)
            
            results = []
            for i, (distance, index) in enumerate(zip(D[0], I[0]), 1):
                if index < len(self.atlas_data['node_list']):
                    node_id = self.atlas_data['node_list'][index]
                    node_data = self.atlas_data['KG'].nodes[node_id]
                    
                    result = f"{node_data.get('id', node_id)} ({node_data.get('type', 'unknown')}): {node_data.get('text', '')}"
                    results.append(result)
                    print(f"   {i}. {result} (similarity: {1-distance:.3f})")
            
            return results
            
        except Exception as e:
            print(f"âŒ Node Retriever failed: {e}")
            import traceback
            traceback.print_exc()
            return []
    
    def run_benchmark_queries(self, test_queries: List[str]) -> Dict[str, Any]:
        """è¿è¡ŒbenchmarkæŸ¥è¯¢"""
        print("\nğŸš€ Running RAG Benchmark Tests")
        print("=" * 50)
        
        results = {
            'simple_graph': {},
            'node_retriever': {},
            'queries': test_queries
        }
        
        for query in test_queries:
            print(f"\nğŸ“ Query: {query}")
            print("-" * 30)
            
            # æµ‹è¯•SimpleGraphRetriever
            simple_results = self.test_simple_graph_retriever(query)
            results['simple_graph'][query] = simple_results
            
            print()
            
            # æµ‹è¯•NodeRetriever
            node_results = self.test_node_retriever(query)
            results['node_retriever'][query] = node_results
            
            print()
        
        return results
    
    def save_results(self, results: Dict[str, Any], output_file: str):
        """ä¿å­˜æµ‹è¯•ç»“æœ"""
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ Results saved to: {output_file}")


def create_test_queries_for_dulce():
    """ä¸ºDulceæ•°æ®åˆ›å»ºæµ‹è¯•æŸ¥è¯¢"""
    return [
        "Who is Agent Alex Mercer?",
        "What is Operation: Dulce?",
        "What is the Paranormal Military Squad?",
        "Who are the team members involved?",
        "What happens in the briefing room?",
        "What are the protocols mentioned?",
        "Who shows compliance in the team?",
        "What anomalies are being investigated?"
    ]


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒŸ NewWork Concept Graph RAG Benchmark")
    print("=" * 60)
    
    try:
        # 1. åŠ è½½NewWorké…ç½®
        print("ğŸ“‹ Loading NewWork configuration...")
        config_loader = ConfigLoader()
        config_loader.print_config_summary()
        
        # 2. è½¬æ¢æ¦‚å¿µå›¾è°±
        print("\nğŸ”„ Converting concept graph...")
        converter = NewWorkToAtlasConverter("output/simple_test")
        atlas_data = converter.convert_to_atlas_format()
        
        # 3. åˆå§‹åŒ–RAGæµ‹è¯•å™¨
        print("\nğŸ¤– Initializing RAG tester...")
        rag_tester = NewWorkRAGTester(config_loader, atlas_data)
        
        # 4. åˆ›å»ºæµ‹è¯•æŸ¥è¯¢
        test_queries = create_test_queries_for_dulce()
        print(f"\nğŸ“ Created {len(test_queries)} test queries")
        
        # 5. è¿è¡Œbenchmarkæµ‹è¯•
        results = rag_tester.run_benchmark_queries(test_queries)
        
        # 6. ä¿å­˜ç»“æœ
        output_file = "output/simple_test/rag_benchmark_results.json"
        rag_tester.save_results(results, output_file)
        
        print("\nğŸ‰ RAG Benchmark completed successfully!")
        print(f"ğŸ“Š Results saved to: {output_file}")
        
        # 7. æ˜¾ç¤ºæ‘˜è¦
        print(f"\nğŸ“ˆ Summary:")
        print(f"   ğŸ“Š Graph: {len(atlas_data['node_list'])} nodes, {len(atlas_data['edge_list'])} edges")
        print(f"   ğŸ” Queries tested: {len(test_queries)}")
        print(f"   ğŸ¤– RAG methods: SimpleGraphRetriever, NodeRetriever")
        
    except KeyboardInterrupt:
        print("\nâš ï¸ Benchmark interrupted by user")
    except Exception as e:
        print(f"\nâŒ Benchmark failed: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()