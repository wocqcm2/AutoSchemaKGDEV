#!/usr/bin/env python3
"""
Direct Concept Extractor
ç›´æ¥ä»æ–‡ç« æå–æ¦‚å¿µçš„æ ¸å¿ƒç±»
"""

import os
import json
import csv
import re
import hashlib
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Tuple
from tqdm import tqdm
import json_repair
from datasets import load_dataset
from concurrent.futures import ThreadPoolExecutor

from direct_concept_prompt import DIRECT_CONCEPT_INSTRUCTIONS
from direct_concept_config import DirectConceptConfig


class TextChunker:
    """æ–‡æœ¬åˆ†å—å¤„ç†å™¨"""
    
    def __init__(self, chunk_size: int = 1024, overlap: int = 100):
        self.chunk_size = chunk_size
        self.overlap = overlap
    
    def chunk_text(self, text: str) -> List[str]:
        """å°†é•¿æ–‡æœ¬åˆ†å—"""
        if len(text) <= self.chunk_size:
            return [text]
        
        chunks = []
        start = 0
        
        while start < len(text):
            end = start + self.chunk_size
            
            # å°è¯•åœ¨å¥å·å¤„åˆ†å‰²
            if end < len(text):
                # å‘åæŸ¥æ‰¾å¥å·
                sentence_end = text.rfind('.', start, end)
                if sentence_end > start + self.chunk_size // 2:
                    end = sentence_end + 1
            
            chunk = text[start:end].strip()
            if chunk:
                chunks.append(chunk)
            
            # è®¡ç®—ä¸‹ä¸€ä¸ªå—çš„èµ·å§‹ä½ç½®ï¼Œè€ƒè™‘é‡å 
            start = max(end - self.overlap, start + 1)
            
            if start >= len(text):
                break
        
        return chunks


class ConceptDataProcessor:
    """æ¦‚å¿µæ•°æ®å¤„ç†å™¨"""
    
    def __init__(self, config: DirectConceptConfig):
        self.config = config
        self.chunker = TextChunker(config.text_chunk_size, config.chunk_overlap)
    
    def prepare_dataset(self, raw_dataset) -> List[Dict[str, Any]]:
        """å‡†å¤‡æ•°æ®é›†ç”¨äºæ¦‚å¿µæå–"""
        processed_samples = []
        
        for item in tqdm(raw_dataset, desc="Processing dataset"):
            text = item.get('text', '')
            metadata = item.get('metadata', {})
            
            # æ¸…ç†æ–‡æœ¬
            if self.config.remove_doc_spaces:
                text = re.sub(r'\s+', ' ', text).strip()
            
            # åˆ†å—å¤„ç†é•¿æ–‡æœ¬
            text_chunks = self.chunker.chunk_text(text)
            
            for i, chunk in enumerate(text_chunks):
                chunk_metadata = metadata.copy()
                chunk_metadata['chunk_id'] = i
                chunk_metadata['total_chunks'] = len(text_chunks)
                chunk_metadata['original_length'] = len(text)
                
                processed_samples.append({
                    'text': chunk,
                    'metadata': chunk_metadata,
                    'chunk_id': f"{metadata.get('file_id', 'unknown')}_{i}"
                })
        
        return processed_samples


class ConceptOutputParser:
    """æ¦‚å¿µè¾“å‡ºè§£æå™¨"""
    
    def __init__(self, config: DirectConceptConfig):
        self.config = config
    
    def parse_concept_output(self, output: str) -> Dict[str, Any]:
        """è§£æLLMè¾“å‡ºçš„æ¦‚å¿µæ•°æ®"""
        try:
            # ä½¿ç”¨json_repairæ¥ä¿®å¤å¯èƒ½æŸåçš„JSON
            parsed_data = json_repair.loads(output)
            
            # éªŒè¯æ•°æ®æ ¼å¼
            if self.config.extraction_mode == "passage_concept":
                return self._validate_passage_concept(parsed_data)
            elif self.config.extraction_mode == "hierarchical_concept":
                return self._validate_hierarchical_concept(parsed_data)
            
        except Exception as e:
            print(f"Error parsing concept output: {e}")
            return {"concepts": [], "relationships": []}
    
    def _validate_passage_concept(self, data: Dict) -> Dict:
        """éªŒè¯passage_conceptæ ¼å¼çš„æ•°æ®"""
        validated = {"concepts": [], "relationships": []}
        
        # éªŒè¯concepts
        if "concepts" in data and isinstance(data["concepts"], list):
            for concept in data["concepts"]:
                if self._is_valid_concept(concept):
                    validated["concepts"].append(concept)
        
        # éªŒè¯relationships
        if "relationships" in data and isinstance(data["relationships"], list):
            for rel in data["relationships"]:
                if self._is_valid_relationship(rel):
                    validated["relationships"].append(rel)
        
        return validated
    
    def _validate_hierarchical_concept(self, data: Dict) -> Dict:
        """éªŒè¯hierarchical_conceptæ ¼å¼çš„æ•°æ®"""
        validated = {
            "specific_concepts": [],
            "general_concepts": [],
            "abstract_concepts": [],
            "hierarchical_relations": []
        }
        
        # éªŒè¯å„çº§åˆ«æ¦‚å¿µ
        for level in ["specific_concepts", "general_concepts", "abstract_concepts"]:
            if level in data and isinstance(data[level], list):
                for concept in data[level]:
                    if self._is_valid_simple_concept(concept):
                        validated[level].append(concept)
        
        # éªŒè¯å±‚æ¬¡å…³ç³»
        if "hierarchical_relations" in data and isinstance(data["hierarchical_relations"], list):
            for rel in data["hierarchical_relations"]:
                if self._is_valid_hierarchical_relation(rel):
                    validated["hierarchical_relations"].append(rel)
        
        return validated
    
    def _is_valid_concept(self, concept: Dict) -> bool:
        """éªŒè¯conceptæ˜¯å¦æœ‰æ•ˆ"""
        required_fields = ["name", "type", "abstraction_level"]
        return all(field in concept for field in required_fields)
    
    def _is_valid_simple_concept(self, concept: Dict) -> bool:
        """éªŒè¯ç®€å•conceptæ˜¯å¦æœ‰æ•ˆ"""
        required_fields = ["name", "type"]
        return all(field in concept for field in required_fields)
    
    def _is_valid_relationship(self, relationship: Dict) -> bool:
<<<<<<< HEAD
        """éªŒè¯relationshipæ˜¯å¦æœ‰æ•ˆ"""
        required_fields = ["source", "target", "relation"]
        return all(field in relationship for field in required_fields)
=======
        """éªŒè¯relationshipæ˜¯å¦æœ‰æ•ˆï¼Œä¸¥æ ¼ç¦æ­¢è‡ªå¼•ç”¨"""
        required_fields = ["source", "target", "relation"]
        
        # åŸºç¡€å­—æ®µéªŒè¯
        if not all(field in relationship for field in required_fields):
            return False
        
        # ğŸ”¥ å…³é”®ï¼šä¸¥æ ¼ç¦æ­¢è‡ªå¼•ç”¨å…³ç³»
        source = str(relationship["source"]).strip().lower()
        target = str(relationship["target"]).strip().lower()
        
        if source == target:
            if self.config.debug_mode:
                print(f"âŒ Rejected self-referential relationship: {source} -> {target}")
            return False
        
        # éªŒè¯å…³ç³»ç±»å‹æœ‰æ•ˆæ€§
        valid_relations = {
            "contains", "belongs_to", "causes", "leads_to", "is_part_of", 
            "relates_to", "influences", "located_in", "is_a", "has", "uses"
        }
        
        relation = str(relationship["relation"]).strip().lower()
        if relation not in valid_relations:
            if self.config.debug_mode:
                print(f"âš ï¸ Unknown relation type: {relation}")
        
        return True
    
    def _filter_and_deduplicate_relationships(self, relationships: List[Dict]) -> List[Dict]:
        """è¿‡æ»¤å’Œå»é‡å…³ç³»ï¼Œç¡®ä¿é«˜è´¨é‡"""
        if not relationships:
            return []
        
        filtered = []
        seen_relations = set()
        
        for rel in relationships:
            # å…ˆéªŒè¯æœ‰æ•ˆæ€§ï¼ˆåŒ…æ‹¬åè‡ªå¼•æ£€æŸ¥ï¼‰
            if not self._is_valid_relationship(rel):
                continue
            
            # æ ‡å‡†åŒ–å…³ç³»è¡¨ç¤ºç”¨äºå»é‡
            source = str(rel["source"]).strip().lower()
            target = str(rel["target"]).strip().lower()
            relation = str(rel["relation"]).strip().lower()
            
            # åˆ›å»ºå…³ç³»ç­¾åï¼ˆè€ƒè™‘åŒå‘å…³ç³»ï¼‰
            rel_signature = tuple(sorted([source, target]) + [relation])
            
            if rel_signature not in seen_relations:
                seen_relations.add(rel_signature)
                filtered.append(rel)
            elif self.config.debug_mode:
                print(f"ğŸ”„ Deduplicated relationship: {source} -{relation}-> {target}")
        
        return filtered
>>>>>>> 0ff854f19280eadc04f4289414abf37019510f1e
    
    def _is_valid_hierarchical_relation(self, relation: Dict) -> bool:
        """éªŒè¯hierarchical_relationæ˜¯å¦æœ‰æ•ˆ"""
        required_fields = ["child", "parent", "relation_type"]
        return all(field in relation for field in required_fields)


class DirectConceptExtractor:
    """ç›´æ¥æ¦‚å¿µæå–å™¨ä¸»ç±»"""
    
    def __init__(self, model, config: DirectConceptConfig):
        self.config = config
        self.model = model
        self.processor = ConceptDataProcessor(config)
        self.parser = ConceptOutputParser(config)
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(self.config.output_directory, exist_ok=True)
        os.makedirs(f"{self.config.output_directory}/concepts", exist_ok=True)
    
    def load_dataset(self):
        """åŠ è½½æ•°æ®é›†"""
        data_path = Path(self.config.data_directory)
        all_files = os.listdir(data_path)
        
        valid_files = [
            filename for filename in all_files
            if filename.startswith(self.config.filename_pattern) and
            (filename.endswith(".json.gz") or filename.endswith(".json") or 
             filename.endswith(".jsonl") or filename.endswith(".jsonl.gz"))
        ]
        
        print(f"Found data files: {valid_files}")
        dataset_config = {"train": valid_files}
<<<<<<< HEAD
        return load_dataset("json", data_files=dataset_config["train"])
=======
        return load_dataset(self.config.data_directory, data_files=dataset_config["train"])
>>>>>>> 0ff854f19280eadc04f4289414abf37019510f1e
    
    def create_concept_extraction_messages(self, text_batch: List[str]) -> List[List[Dict]]:
        """åˆ›å»ºæ¦‚å¿µæå–çš„æ¶ˆæ¯"""
        messages = []
        
        # è·å–è¯­è¨€å¯¹åº”çš„æŒ‡ä»¤
        instructions = DIRECT_CONCEPT_INSTRUCTIONS.get(
            self.config.language, 
            DIRECT_CONCEPT_INSTRUCTIONS["en"]
        )
        
        system_msg = instructions["system"]
        
        if self.config.extraction_mode == "passage_concept":
            concept_prompt = instructions["passage_concept"]
        else:
            concept_prompt = instructions["hierarchical_concept"]
        
        for text in text_batch:
            user_msg = f"{concept_prompt}\n\n{instructions['passage_start']}\n{text}"
            
            message = [
                {"role": "system", "content": system_msg},
                {"role": "user", "content": user_msg}
            ]
            messages.append(message)
        
        return messages
    
    def extract_concepts_batch(self, text_batch: List[str]) -> List[Dict]:
        """æ‰¹é‡æå–æ¦‚å¿µ"""
        messages = self.create_concept_extraction_messages(text_batch)
        
        try:
            # è°ƒç”¨æ¨¡å‹è¿›è¡Œæ¦‚å¿µæå–
            outputs = self.model.generate_response(
                messages, 
                max_new_tokens=self.config.max_new_tokens,
                temperature=self.config.temperature,
                return_text_only=not self.config.record_usage,
                max_workers=self.config.max_workers
            )
            
            if self.config.record_usage:
                text_outputs = [output[0] for output in outputs]
                usages = [output[1] for output in outputs]
            else:
                text_outputs = outputs
                usages = None
            
            # è§£æè¾“å‡º
            parsed_results = []
            for i, output in enumerate(text_outputs):
                parsed_data = self.parser.parse_concept_output(output)
                
                result = {
                    'concepts': parsed_data.get('concepts', []),
                    'relationships': parsed_data.get('relationships', []),
                    'raw_output': output
                }
                
                if self.config.extraction_mode == "hierarchical_concept":
                    result.update({
                        'specific_concepts': parsed_data.get('specific_concepts', []),
                        'general_concepts': parsed_data.get('general_concepts', []),
                        'abstract_concepts': parsed_data.get('abstract_concepts', []),
                        'hierarchical_relations': parsed_data.get('hierarchical_relations', [])
                    })
                
                if usages:
                    result['usage'] = usages[i]
                
                parsed_results.append(result)
            
            return parsed_results
            
        except Exception as e:
            print(f"Error in concept extraction: {e}")
            return [{"concepts": [], "relationships": []} for _ in text_batch]
    
    def run_extraction(self):
        """è¿è¡Œå®Œæ•´çš„æ¦‚å¿µæå–æµç¨‹"""
        print("ğŸš€ Starting direct concept extraction...")
        
        # åŠ è½½æ•°æ®é›†
        dataset = self.load_dataset()
        processed_data = self.processor.prepare_dataset(dataset["train"])
        
        print(f"ğŸ“Š Processing {len(processed_data)} text chunks")
        
        # åˆ›å»ºè¾“å‡ºæ–‡ä»¶
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        output_file = f"{self.config.output_directory}/concepts/direct_concepts_{timestamp}.json"
        
        all_concepts = []
        all_relationships = []
        
        # æ‰¹å¤„ç†æå–æ¦‚å¿µ
        batch_size = self.config.batch_size_concept
        
        with open(output_file, "w", encoding="utf-8") as f:
            for i in tqdm(range(0, len(processed_data), batch_size), desc="Extracting concepts"):
                batch = processed_data[i:i + batch_size]
                text_batch = [item['text'] for item in batch]
                
                # æå–æ¦‚å¿µ
                concept_results = self.extract_concepts_batch(text_batch)
                
                # ä¿å­˜ç»“æœ
                for j, result in enumerate(concept_results):
                    output_item = {
                        'chunk_id': batch[j]['chunk_id'],
                        'metadata': batch[j]['metadata'],
                        'text': batch[j]['text'],
                        'extracted_concepts': result
                    }
                    
<<<<<<< HEAD
                    # æ”¶é›†æ‰€æœ‰æ¦‚å¿µå’Œå…³ç³»
                    all_concepts.extend(result.get('concepts', []))
                    all_relationships.extend(result.get('relationships', []))
=======
                    # æ”¶é›†æ‰€æœ‰æ¦‚å¿µå’Œå…³ç³»ï¼Œåº”ç”¨è´¨é‡æ§åˆ¶
                    concepts = result.get('concepts', [])
                    relationships = result.get('relationships', [])
                    
                    # ğŸ”¥ å…³ç³»è´¨é‡æ§åˆ¶ï¼šå»é‡å’ŒéªŒè¯
                    filtered_relationships = self._filter_and_deduplicate_relationships(relationships)
                    
                    all_concepts.extend(concepts)
                    all_relationships.extend(filtered_relationships)
>>>>>>> 0ff854f19280eadc04f4289414abf37019510f1e
                    
                    if self.config.debug_mode:
                        print(f"Chunk {batch[j]['chunk_id']}: "
                              f"{len(result.get('concepts', []))} concepts, "
                              f"{len(result.get('relationships', []))} relationships")
                    
                    f.write(json.dumps(output_item, ensure_ascii=False) + "\n")
                    f.flush()
        
        print(f"âœ… Concept extraction completed!")
        print(f"ğŸ“„ Results saved to: {output_file}")
        print(f"ğŸ“Š Total extracted: {len(all_concepts)} concepts, {len(all_relationships)} relationships")
        
        return output_file
    
    def create_concept_csv(self, concept_file: str):
        """å°†æ¦‚å¿µæ•°æ®è½¬æ¢ä¸ºCSVæ ¼å¼"""
        print("ğŸ“Š Converting concepts to CSV...")
        
        csv_output_dir = f"{self.config.output_directory}/concept_csv"
        os.makedirs(csv_output_dir, exist_ok=True)
        
        concepts_csv = f"{csv_output_dir}/concepts_{self.config.filename_pattern}.csv"
        relationships_csv = f"{csv_output_dir}/relationships_{self.config.filename_pattern}.csv"
        
        all_concepts = []
        all_relationships = []
        
        # è¯»å–æ¦‚å¿µæ–‡ä»¶
        with open(concept_file, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    data = json.loads(line)
                    extracted = data['extracted_concepts']
                    
                    # æ”¶é›†æ¦‚å¿µ
                    for concept in extracted.get('concepts', []):
                        concept['source_chunk'] = data['chunk_id']
                        all_concepts.append(concept)
                    
                    # æ”¶é›†å…³ç³»
                    for rel in extracted.get('relationships', []):
                        rel['source_chunk'] = data['chunk_id']
                        all_relationships.append(rel)
        
        # å†™å…¥æ¦‚å¿µCSV
        with open(concepts_csv, 'w', newline='', encoding='utf-8') as f:
            if all_concepts:
                fieldnames = ['name', 'type', 'abstraction_level', 'description', 'source_chunk']
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()
                
                for concept in all_concepts:
                    row = {field: concept.get(field, '') for field in fieldnames}
                    writer.writerow(row)
        
        # å†™å…¥å…³ç³»CSV
        with open(relationships_csv, 'w', newline='', encoding='utf-8') as f:
            if all_relationships:
                fieldnames = ['source', 'target', 'relation', 'description', 'source_chunk']
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()
                
                for rel in all_relationships:
                    row = {field: rel.get(field, '') for field in fieldnames}
                    writer.writerow(row)
        
        print(f"âœ… CSV files created:")
        print(f"   ğŸ“„ Concepts: {concepts_csv}")
        print(f"   ğŸ“„ Relationships: {relationships_csv}")
        
        return concepts_csv, relationships_csv 