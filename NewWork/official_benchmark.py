#!/usr/bin/env python3
"""
Official AutoSchemaKG Benchmark for HotpotQA Knowledge Graph
ä½¿ç”¨AutoSchemaKGå®˜æ–¹æµ‹è¯•ç³»ç»Ÿå’Œæ ‡å‡†æ•°æ®é›†
è®¡ç®—è®ºæ–‡ä¸­çš„æ ‡å‡†æŒ‡æ ‡ï¼šEM, F1, Recall@2, Recall@5
"""

import os
import sys
import json
import logging
from pathlib import Path

# æ·»åŠ è·¯å¾„
sys.path.append('..')
sys.path.append('.')

from config_loader import ConfigLoader, create_model_client
from atlas_rag.evaluation.benchmark import RAGBenchmark, BenchMarkConfig
from atlas_rag.vectorstore.embedding_model import SentenceEmbedding
from atlas_rag.retriever.simple_retriever import SimpleGraphRetriever, SimpleTextRetriever
from atlas_rag.retriever.hipporag import HippoRAGRetriever  
from atlas_rag.retriever.hipporag2 import HippoRAG2Retriever
from atlas_rag.retriever.tog import TogRetriever
from atlas_rag.logging import setup_logger
from sentence_transformers import SentenceTransformer
import networkx as nx
import pandas as pd
import pickle
import numpy as np
import faiss


class HotpotKGDataLoader:
    """åŠ è½½HotpotQAçŸ¥è¯†å›¾è°±æ•°æ®ï¼Œé€‚é…å®˜æ–¹benchmarkæ ¼å¼"""
    
    def __init__(self, kg_path: str = "output/hotpot_kg"):
        self.kg_path = Path(kg_path)
        self.concepts_csv = self.kg_path / "concept_csv" / "concepts_hotpot_kg.csv"
        self.relationships_csv = self.kg_path / "concept_csv" / "relationships_hotpot_kg.csv"
        self.graph_pkl = self.kg_path / "graph" / "hotpot_kg.pkl"
        
    def load_kg_data(self):
        """åŠ è½½çŸ¥è¯†å›¾è°±æ•°æ®"""
        print("ğŸ”„ Loading HotpotQA Knowledge Graph...")
        
        # åŠ è½½NetworkXå›¾
        with open(self.graph_pkl, 'rb') as f:
            G = pickle.load(f)
        
        # åŠ è½½CSVæ•°æ®
        concepts_df = pd.read_csv(self.concepts_csv)
        relationships_df = pd.read_csv(self.relationships_csv)
        
        # æ„å»ºèŠ‚ç‚¹åˆ—è¡¨å’Œæ•°æ®
        node_list = []
        node_dict = {}
        text_dict = {}
        
        for idx, row in concepts_df.iterrows():
            node_id = str(idx)
            node_data = {
                'id': row['id'],
                'text': row['text'],
                'type': row['type'],
                'abstraction_level': row['abstraction_level']
            }
            node_list.append(node_id)
            node_dict[node_id] = node_data
            text_dict[node_id] = row['text']
            
            # ç¡®ä¿èŠ‚ç‚¹åœ¨å›¾ä¸­
            if node_id not in G.nodes:
                G.add_node(node_id, **node_data)
        
        # æ„å»ºè¾¹åˆ—è¡¨
        edge_list = []
        for idx, row in relationships_df.iterrows():
            source_name = row['source']
            target_name = row['target']
            
            # æŸ¥æ‰¾å¯¹åº”çš„èŠ‚ç‚¹ID
            source_id = None
            target_id = None
            
            for node_idx, concept_row in concepts_df.iterrows():
                if concept_row['id'] == source_name:
                    source_id = str(node_idx)
                if concept_row['id'] == target_name:
                    target_id = str(node_idx)
            
            if source_id and target_id:
                edge_list.append((source_id, target_id))
                
                # é‡è¦ï¼šåŒæ—¶æ·»åŠ åˆ°NetworkXå›¾ä¸­ï¼
                edge_data = {
                    'relation': row['relation'],
                    'description': row.get('relation_type', row['relation'])
                }
                G.add_edge(source_id, target_id, **edge_data)
        
        # éªŒè¯å›¾çš„ç»“æ„
        print(f"âœ… Loaded: {len(node_list)} nodes, {len(edge_list)} edges")
        print(f"ğŸ” NetworkX Graph: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges")
        
        # éªŒè¯ä¸€äº›è¾¹æ˜¯å¦çœŸçš„åœ¨å›¾ä¸­
        if edge_list:
            sample_edges = edge_list[:min(3, len(edge_list))]
            for edge in sample_edges:
                if G.has_edge(*edge):
                    print(f"âœ… Sample edge {edge} exists in graph")
                else:
                    print(f"âŒ Sample edge {edge} NOT in graph!")
        
        # éªŒè¯èŠ‚ç‚¹æ•°æ®
        if node_list:
            sample_node = node_list[0]
            if sample_node in G.nodes:
                node_data = G.nodes[sample_node]
                print(f"âœ… Sample node {sample_node}: {list(node_data.keys())}")
            else:
                print(f"âŒ Sample node {sample_node} NOT in graph!")
        
        # ä¸ºå®˜æ–¹retrieveræ·»åŠ æ›´å¤šå¿…éœ€çš„æ•°æ®å­—æ®µ
        return {
            'KG': G,
            'node_list': node_list,
            'edge_list': edge_list,
            'text_dict': text_dict,
            'original_text_dict_with_node_id': text_dict,
            'node_dict': node_dict,
            'edge_dict': {edge: {'relation': G.edges[edge].get('relation', 'related_to')} for edge in edge_list if G.has_edge(*edge)},
            'original_text_dict': text_dict,
            'passage_dict': text_dict  # SimpleTextRetriever éœ€è¦
        }


def create_embeddings_and_indices(data, sentence_encoder):
    """åˆ›å»ºembeddingså’ŒFAISSç´¢å¼•"""
    print("ğŸ”„ Creating embeddings and FAISS indices...")
    
    # åˆ›å»ºèŠ‚ç‚¹embeddings
    node_texts = []
    for node_id in data['node_list']:
        if node_id in data['KG'].nodes:
            node_data = data['KG'].nodes[node_id]
            text = node_data.get('text', node_data.get('id', str(node_id)))
            node_texts.append(text)
        else:
            node_texts.append(str(node_id))
    
    # åˆ›å»ºè¾¹embeddings
    edge_texts = []
    for edge in data['edge_list']:
        if len(edge) >= 2:
            source_data = data['KG'].nodes.get(edge[0], {})
            target_data = data['KG'].nodes.get(edge[1], {})
            edge_data = data['KG'].edges.get(edge, {})
            
            source_text = source_data.get('text', source_data.get('id', str(edge[0])))
            target_text = target_data.get('text', target_data.get('id', str(edge[1])))
            relation = edge_data.get('relation', 'related_to')
            
            edge_text = f"{source_text} {relation} {target_text}"
            edge_texts.append(edge_text)
    
    # è®¡ç®—embeddings
    if node_texts:
        node_embeddings = sentence_encoder.encode(node_texts)
        if len(node_embeddings.shape) == 1:
            node_embeddings = node_embeddings.reshape(1, -1)
    else:
        node_embeddings = np.zeros((1, 384))
    
    if edge_texts:
        edge_embeddings = sentence_encoder.encode(edge_texts)
        if len(edge_embeddings.shape) == 1:
            edge_embeddings = edge_embeddings.reshape(1, -1)
    else:
        edge_embeddings = np.zeros((1, 384))
    
    # åˆ›å»ºFAISSç´¢å¼•
    if node_embeddings.shape[0] > 0 and node_embeddings.shape[1] > 0:
        node_index = faiss.IndexFlatIP(node_embeddings.shape[1])
        normalized_node_emb = node_embeddings / np.linalg.norm(node_embeddings, axis=1, keepdims=True)
        node_index.add(normalized_node_emb.astype('float32'))
    else:
        node_index = faiss.IndexFlatIP(384)
    
    if edge_embeddings.shape[0] > 0 and edge_embeddings.shape[1] > 0:
        edge_index = faiss.IndexFlatIP(edge_embeddings.shape[1])
        normalized_edge_emb = edge_embeddings / np.linalg.norm(edge_embeddings, axis=1, keepdims=True)
        edge_index.add(normalized_edge_emb.astype('float32'))
    else:
        edge_index = faiss.IndexFlatIP(384)
    
    # æ›´æ–°æ•°æ®
    data.update({
        'node_embeddings': node_embeddings,
        'edge_embeddings': edge_embeddings,
        'text_embeddings': node_embeddings,  # ç”¨äºæŸäº›retriever
        'node_faiss_index': node_index,
        'edge_faiss_index': edge_index,
    })
    
    print(f"âœ… Created embeddings: nodes{node_embeddings.shape}, edges{edge_embeddings.shape}")
    return data


def setup_official_benchmark(dataset_name: str, question_file: str, num_samples: int = 50):
    """é…ç½®å®˜æ–¹benchmark"""
    print(f"\nâš™ï¸ Setting up official AutoSchemaKG benchmark...")
    print(f"ğŸ“Š Dataset: {dataset_name}")
    print(f"ğŸ“ Question file: {question_file}")
    print(f"ğŸ“Š Samples: {num_samples}")
    
    config_loader = ConfigLoader()
    
    # æ£€æŸ¥é—®é¢˜æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not Path(question_file).exists():
        raise FileNotFoundError(f"Question file not found: {question_file}")
    
    # åˆ›å»ºå®˜æ–¹benchmarké…ç½®
    benchmark_config = BenchMarkConfig(
        dataset_name=dataset_name,
        question_file=question_file,
        include_concept=True,
        include_events=True,
        reader_model_name=config_loader.config_data.get('models', {}).get('qwen_235b', 'qwen'),
        encoder_model_name="all-MiniLM-L6-v2",
        number_of_samples=num_samples,
        react_max_iterations=3
    )
    
    # è®¾ç½®logger
    logger = setup_logger(benchmark_config)
    
    return benchmark_config, logger, config_loader


def setup_retrievers(data, sentence_encoder, llm_generator):
    """è®¾ç½®retrieveråˆ—è¡¨"""
    print("ğŸ”§ Setting up retrievers for official benchmark...")
    
    retrievers = []
    
    try:
        # 1. SimpleGraphRetriever
        simple_graph = SimpleGraphRetriever(
            llm_generator=llm_generator,
            sentence_encoder=sentence_encoder,
            data=data
        )
        retrievers.append(simple_graph)
        print("âœ… SimpleGraphRetriever added")
        
        # 2. SimpleTextRetriever
        passage_dict = data.get('text_dict', {})
        simple_text = SimpleTextRetriever(
            passage_dict=passage_dict,
            sentence_encoder=sentence_encoder,
            data=data
        )
        retrievers.append(simple_text)
        print("âœ… SimpleTextRetriever added")
        
        # 3. TogRetriever
        try:
            tog_retriever = TogRetriever(
                llm_generator=llm_generator,
                sentence_encoder=sentence_encoder,
                data=data
            )
            retrievers.append(tog_retriever)
            print("âœ… TogRetriever added")
        except Exception as e:
            print(f"âš ï¸ TogRetriever failed: {e}")
        
        # 4. HippoRAGRetriever
        try:
            # ä¸ºHippoRAGå‡†å¤‡æ•°æ®
            hippo_data = data.copy()
            file_id_to_node_id = {}
            
            for node_id in data['node_list']:
                if node_id in hippo_data['KG'].nodes:
                    hippo_data['KG'].nodes[node_id]['type'] = 'passage'
                    file_id = f"file_{node_id}"
                    hippo_data['KG'].nodes[node_id]['file_id'] = file_id
                    file_id_to_node_id[file_id] = [node_id]
            
            # æ·»åŠ  HippoRAG éœ€è¦çš„æ˜ å°„
            hippo_data['file_id_to_node_id'] = file_id_to_node_id
            
            hipporag = HippoRAGRetriever(
                llm_generator=llm_generator,
                sentence_encoder=sentence_encoder,
                data=hippo_data
            )
            retrievers.append(hipporag)
            print("âœ… HippoRAGRetriever added")
        except Exception as e:
            print(f"âš ï¸ HippoRAGRetriever failed: {e}")
            import traceback
            traceback.print_exc()
        
        # 5. HippoRAG2Retriever
        try:
            hipporag2 = HippoRAG2Retriever(
                llm_generator=llm_generator,
                sentence_encoder=sentence_encoder,
                data=data
            )
            retrievers.append(hipporag2)
            print("âœ… HippoRAG2Retriever added")
        except Exception as e:
            print(f"âš ï¸ HippoRAG2Retriever failed: {e}")
            
    except Exception as e:
        print(f"âŒ Setup retrievers failed: {e}")
        import traceback
        traceback.print_exc()
    
    print(f"ğŸ“‹ Total retrievers setup: {len(retrievers)}")
    return retrievers


def run_official_benchmark(dataset_name: str = "hotpotqa", 
                          question_file: str = "../benchmark_data/hotpotqa.json",
                          num_samples: int = 50):
    """è¿è¡Œå®˜æ–¹AutoSchemaKG benchmark"""
    print("ğŸš€ Starting Official AutoSchemaKG Benchmark")
    print("=" * 80)
    print("ğŸ¯ This will compute standard metrics: EM, F1, Recall@2, Recall@5")
    print("=" * 80)
    
    try:
        # 1. è®¾ç½®å®˜æ–¹benchmark
        benchmark_config, logger, config_loader = setup_official_benchmark(
            dataset_name, question_file, num_samples
        )
        
        # 2. åŠ è½½HotpotQAçŸ¥è¯†å›¾è°±
        kg_loader = HotpotKGDataLoader()
        data = kg_loader.load_kg_data()
        
        # 3. åˆ›å»ºsentence encoder
        transformer = SentenceTransformer("all-MiniLM-L6-v2")
        sentence_encoder = SentenceEmbedding(transformer)
        
        # 4. åˆ›å»ºembeddingså’Œç´¢å¼•
        data = create_embeddings_and_indices(data, sentence_encoder)
        
        # 5. åˆ›å»ºLLMç”Ÿæˆå™¨
        llm_generator = create_model_client(config_loader)
        
        # 6. è®¾ç½®retrievers
        retrievers = setup_retrievers(data, sentence_encoder, llm_generator)
        
        if not retrievers:
            print("âŒ No retrievers available, cannot run benchmark")
            return
        
        # 7. è¿è¡Œå®˜æ–¹benchmark
        print(f"\nğŸš€ Running Official AutoSchemaKG Benchmark...")
        print(f"ğŸ“Š Dataset: {dataset_name}")
        print(f"ğŸ“Š Question file: {question_file}")
        print(f"ğŸ“Š Samples: {num_samples}")
        print(f"ğŸ“Š Retrievers: {[r.__class__.__name__ for r in retrievers]}")
        print("=" * 60)
        
        # åˆ›å»ºå¹¶è¿è¡Œå®˜æ–¹RAGBenchmark
        benchmark = RAGBenchmark(config=benchmark_config, logger=logger)
        benchmark.run(retrievers, llm_generator)
        
        print(f"\nâœ… Official benchmark completed!")
        print(f"ğŸ“Š Results saved to: ./result/{dataset_name}/")
        print("ğŸ“‹ Standard metrics calculated: EM, F1, Recall@2, Recall@5")
        
        # 8. æ‰“å°æ‘˜è¦
        print_benchmark_summary(dataset_name, retrievers, num_samples)
        
    except Exception as e:
        print(f"âŒ Official benchmark failed: {e}")
        import traceback
        traceback.print_exc()


def print_benchmark_summary(dataset_name: str, retrievers, num_samples: int):
    """æ‰“å°æµ‹è¯•æ‘˜è¦"""
    print("\n" + "="*80)
    print("ğŸ“Š OFFICIAL AUTOSCHEMAKG BENCHMARK SUMMARY")
    print("="*80)
    print(f"ğŸ—ƒï¸  Dataset: {dataset_name}")
    print(f"ğŸ“Š Samples: {num_samples}")
    print(f"ğŸ¤– Knowledge Graph: HotpotQA (1002 concepts)")
    print(f"ğŸ”§ Tested Retrievers:")
    for i, retriever in enumerate(retrievers, 1):
        print(f"   {i}. {retriever.__class__.__name__}")
    print(f"ğŸ“Š Standard Metrics: EM, F1, Recall@2, Recall@5")
    print(f"ğŸ’¾ Results Location: ./result/{dataset_name}/")
    print("="*80)
    print("ğŸ¯ This matches the AutoSchemaKG paper evaluation setup!")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸŒŸ Official AutoSchemaKG Benchmark for HotpotQA Knowledge Graph")
    print("=" * 80)
    print("ğŸ¯ Using official benchmark system with standard metrics")
    print("=" * 80)
    
    # æ£€æŸ¥å¯ç”¨çš„æµ‹è¯•æ•°æ®é›†
    available_datasets = []
    
    # HotpotQA æ˜¯é¦–é€‰ï¼ˆä¸æ‚¨çš„KGåŒ¹é…ï¼‰
    if Path("../benchmark_data/hotpotqa.json").exists():
        available_datasets.append(("hotpotqa", "../benchmark_data/hotpotqa.json"))
    
    # å…¶ä»–æ•°æ®é›†
    if Path("../benchmark_data/musique_sample.json").exists():
        available_datasets.append(("musique", "../benchmark_data/musique_sample.json"))
    
    if Path("../working_data/2wikimultihopqa.json").exists():
        available_datasets.append(("2wikimultihopqa", "../working_data/2wikimultihopqa.json"))
    
    if not available_datasets:
        print("âŒ No official test datasets found!")
        print("ğŸ’¡ Expected locations:")
        print("   - ../benchmark_data/hotpotqa.json (RECOMMENDED)")
        print("   - ../benchmark_data/musique_sample.json")
        print("   - ../working_data/2wikimultihopqa.json")
        return
    
    print(f"\nğŸ“‹ Available official datasets:")
    for i, (name, path) in enumerate(available_datasets, 1):
        print(f"   {i}. {name} ({path})")
    
    try:
        choice = input(f"\nSelect dataset (1-{len(available_datasets)}) [1]: ").strip() or "1"
        dataset_idx = int(choice) - 1
        
        if 0 <= dataset_idx < len(available_datasets):
            dataset_name, question_file = available_datasets[dataset_idx]
            
            # è·å–æ ·æœ¬æ•°é‡ï¼ˆHotpotQAæ¨èè¾ƒå°‘æ ·æœ¬è¿›è¡Œåˆå§‹æµ‹è¯•ï¼‰
            default_samples = "20" if dataset_name == "hotpotqa" else "50"
            try:
                samples = int(input(f"Number of samples [{default_samples}]: ").strip() or default_samples)
            except ValueError:
                samples = int(default_samples)
            
            # è¿è¡Œå®˜æ–¹benchmark
            run_official_benchmark(dataset_name, question_file, samples)
            
        else:
            print("âŒ Invalid choice, using first dataset")
            dataset_name, question_file = available_datasets[0]
            default_samples = 20 if dataset_name == "hotpotqa" else 50
            run_official_benchmark(dataset_name, question_file, default_samples)
            
    except KeyboardInterrupt:
        print("\nâš ï¸ Benchmark interrupted by user")
    except Exception as e:
        print(f"\nâŒ Benchmark failed: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()